import os
import argparse

# ====== C·∫§U H√åNH ======
DATA_DIR = "data"
VIDEO_PATH = os.path.join(DATA_DIR, "input_video.mp4")
JSON_PATH = os.path.join(DATA_DIR, "hand_keypoints.json")
MODEL_PATH = os.path.join(DATA_DIR, "gesture_classifier.joblib")
KEYPOINT_DIR = os.path.join(DATA_DIR, "keypoints")

# ====== TASK 1: Tr√≠ch xu·∫•t kh·ªõp tay ======
def run_task1():
    print("üîç Task 1: Tr√≠ch xu·∫•t kh·ªõp tay t·ª´ video...")
    from t1_extract_hand_pose import extract_hand_keypoints
    extract_hand_keypoints(VIDEO_PATH, JSON_PATH)

# ====== TASK 2: M√¥ ph·ªèng l·∫°i chuy·ªÉn ƒë·ªông ======
def run_task2():
    print("üéûÔ∏è Task 2: M√¥ ph·ªèng l·∫°i chuy·ªÉn ƒë·ªông t·ª´ JSON...")
    from t2_replay_hand_pose import replay_hand_keypoints
    replay_hand_keypoints(JSON_PATH)

# ====== TASK 3: Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n lo·∫°i ======
def run_task3():
    print("ü§ñ Task 3: Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n lo·∫°i c·ª≠ ch·ªâ...")
    from t3_train_gesture_classifier import train_and_evaluate

    if not os.path.exists(KEYPOINT_DIR):
        print(f"[‚ùå] Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {KEYPOINT_DIR}")
        return

    train_and_evaluate(KEYPOINT_DIR, MODEL_PATH)

# ====== MAIN ENTRY ======
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="AI4LI - ƒêi·ªÅu ph·ªëi pipeline")
    parser.add_argument("--task", type=int, choices=[1, 2, 3], required=True, help="Ch·ªçn task ƒë·ªÉ ch·∫°y (1-3)")
    args = parser.parse_args()

    if args.task == 1:
        run_task1()
    elif args.task == 2:
        run_task2()
    elif args.task == 3:
        run_task3()
